{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) for Social Sphere Project\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "The **Social Sphere Project** aims to analyze social media usage patterns and their impact on mental health and sleep among different demographics. This notebook is dedicated to the Exploratory Data Analysis (EDA) phase, where we will gain insights into the dataset by examining the distributions and relationships among key variables. This analysis will help us understand the data better and prepare it for subsequent modeling phases.\n",
    "\n",
    "## EDA Objectives\n",
    "\n",
    "- **Profile Demographics**: Analyze age, gender, academic level, and country distributions.\n",
    "- **Social-Media Behaviors**: Explore usage patterns and their relationships with mental health and sleep.\n",
    "- **Target Variables**: Investigate patterns related to `Conflicts_Over_Social_Media` and `Addicted_Score`.\n",
    "- **Cross-Country and Platform Analysis**: Assess differences across countries and platforms.\n",
    "- **Data Preprocessing**: Handle missing values, encode categorical variables, detect outliers, and flag potential data biases.\n",
    "\n",
    "## Structure\n",
    "\n",
    "1. **Data Ingestion & Cleaning**: Load and clean the dataset, handle missing values, and prepare the data for analysis.\n",
    "2. **Univariate Analysis**: Examine the distribution of individual variables.\n",
    "3. **Bivariate/Multivariate Analysis**: Explore relationships between variables.\n",
    "4. **Target-aware Exploration**: Analyze the distribution of target variables across demographics and behaviors.\n",
    "5. **Bias & Outlier Detection**: Identify demographic skews and outliers.\n",
    "6. **Pre-Clustering with PCA & UMAP**: Visualize naturally separated behavioral segments.\n",
    "\n",
    "This EDA will provide a comprehensive understanding of the dataset, which is crucial for effective modeling and analysis in later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# System & Data Handling\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "# Data Loading\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting & Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import map_to_continent\n",
    "\n",
    "# Constants\n",
    "FIGSIZE = (16, 5)\n",
    "FIGSIZE_LONG=(20, 6)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Descriptions\n",
    "\n",
    "- **Student_ID**: A unique integer identifier assigned to each survey respondent to enable de-duplication and track individual records without revealing personal information.  \n",
    "- **Age**: The student’s age in completed years at the time of the survey, used to segment analysis by age group and control for developmental differences.  \n",
    "- **Gender**: The student’s self-reported gender, recorded as “Male” or “Female” to allow for demographic breakdowns in usage and outcome measures.  \n",
    "- **Academic_Level**: The highest level of education the respondent is currently enrolled in, with categories: “High School,” “Undergraduate,” or “Graduate,” facilitating stratified analyses by academic stage.  \n",
    "- **Country**: The country of residence where the student completed the survey, enabling cross-country comparisons of social media behaviors and impacts.  \n",
    "- **Avg_Daily_Usage_Hours**: The average number of hours per day the student spends on social media platforms, calculated from self-reported weekday and weekend usage estimates.  \n",
    "- **Most_Used_Platform**: The social media platform on which the student spends the most time (e.g., Instagram, Facebook, TikTok), used to examine platform-specific effects.  \n",
    "- **Affects_Academic_Performance**: A binary indicator (“Yes”/“No”) reflecting whether the student perceives their social media use as having a negative impact on their academic performance.  \n",
    "- **Sleep_Hours_Per_Night**: The respondent’s average nightly sleep duration in hours, provided to investigate correlations between screen time and sleep quality/quantity.  \n",
    "- **Mental_Health_Score**: A self-rated integer from 1 (poor) to 10 (excellent) indicating overall mental well-being, allowing assessment of potential associations with social media habits.  \n",
    "- **Relationship_Status**: The student’s current romantic relationship status, categorized as “Single,” “In Relationship,” or “Complicated,” to explore social media’s impact on interpersonal dynamics.  \n",
    "- **Conflicts_Over_Social_Media**: The number of arguments or disagreements the student reports having had with family, friends, or partners due to their social media use, serving as a proxy for social friction.  \n",
    "- **Addicted_Score**: A composite score from 1 (low addiction) to 10 (high addiction) based on a standardized survey scale (e.g., Bergen Social Media Addiction Scale), quantifying the degree of problematic usage.\n",
    "\n",
    "Features relying on student's self-perception:\n",
    "- **Mental_Health_Score**\n",
    "- **Relationship_Status**\n",
    "- **Affects_Academic_Performance**  \n",
    "This features are based on the student's self-perception and are not directly observable. We should be careful with the interpretation of these features and analyze their impact on the models predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Loading the Data\n",
    "\n",
    "The dataset is sourced from Kaggle and contains information about social media usage patterns, demographics, and their impact on mental health and relationships. It includes various features such as age, gender, academic level, country, daily usage hours, preferred platforms, and metrics related to mental health and addiction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"adilshamim8/social-media-addiction-vs-relationships\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file = os.listdir(path)[0]\n",
    "file_path = os.path.join(path, file)\n",
    "# copy the file to data folder\n",
    "shutil.copy(file_path, \"../data/data.csv\")\n",
    "\n",
    "df_data = pd.read_csv(\"../data/data.csv\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name refactoring\n",
    "df_data.rename(columns={\n",
    "    'Sleep_Hours_Per_Night': 'Sleep_Hrs',\n",
    "    'Social_Media_Usage_Hours': 'Soc_Media_Usage',\n",
    "    'Avg_Daily_Usage_Hours': 'Daily_Usage',\n",
    "    'Conflicts_Over_Social_Media': 'Conflicts',\n",
    "    'Mental_Health_Score': 'Mental_Health',\n",
    "    # 'Addicted_Score': 'Adcdicted_Score',\n",
    "    # 'Relationship_Status': 'Rel_Status',\n",
    "    'Affects_Academic_Performance': 'Academic_Affects',\n",
    "    'Most_Used_Platform': 'Platform'\n",
    "    # 'Academic_Level': 'Acad_Level'\n",
    "}, inplace=True)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the data shape, null values\n",
    "- There are 705 rows and 13 columns in the dataset.\n",
    "- No null values exist in any of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data shape, null values, and column types\n",
    "print(\"data shape: \", df_data.shape)\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null values inspection\n",
    "The dataset has no null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any column has null values\n",
    "if df_data.isnull().sum().any():\n",
    "    print(\"null values: \", df_data.isnull().sum())\n",
    "else:\n",
    "    print(\"no null values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting duplicates\n",
    "- There are no duplicate rows or duplicates by Student_ID in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting duplicates\n",
    "\n",
    "print(f\"Number of duplicate rows: {df_data.duplicated().sum()}\")\n",
    "\n",
    "# inspecting duplicates by Student_ID\n",
    "print(f\"Number of duplicates by Student_ID: {len(df_data[df_data.duplicated(subset=['Student_ID'])].index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Column types\n",
    "- Column types are set to the correct data types.\n",
    "- The **categorical columns** are 'Gender', 'Academic_Level', 'Country', 'Most_Used_Platform', 'Affects_Academic_Performance', 'Relationship_Status'\n",
    "- The **numerical columns** are 'Age', 'Sleep_Hours_Per_Night', 'Social_Media_Usage_Hours', 'Conflicts_Over_Social_Media', 'Addicted_Score'\n",
    "- The student_id is dropped as it is not a relevant feature for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df_data.select_dtypes(include=['object']).columns\n",
    "cat_cols = [col for col in cat_cols if col not in ['Date', 'Time']]\n",
    "num_cols = df_data.select_dtypes(include=['int64', 'float64']).columns.drop('Student_ID').tolist()\n",
    "\n",
    "\n",
    "print('categorical columns: \\n', cat_cols)\n",
    "print('\\n numerical columns: \\n', num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the summary statistics\n",
    "- The age range is from 18 to 24, which is consistent with the target population of students aged 16–25. The average age is ~20.\n",
    "- The participants spend ~4.9 hours on social media per day, ranging from 1.5 to 8.5 hours.\n",
    "- The average sleep duration is ~6.8 hours, ranging from 4 to 12 hours.\n",
    "- The average conflicts over social media score is ~2.8, ranging from 0 to 5.\n",
    "- The average addicted score is ~1.5, ranging from 2 to 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for numerical columns\n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data has no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(f'Number of duplicates: {df_data.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical columns\n",
    "- The data is collected from ~100 countries.\n",
    "- Academic levels are: 'Undergraduate', 'Graduate', 'High School'\n",
    "- Gender: 'Female', 'Male'\n",
    "- Most used platforms are: 'Instagram', 'Twitter', 'TikTok', 'YouTube', 'Facebook', 'LinkedIn', 'Snapchat', 'LINE', 'KakaoTalk', 'VKontakte', 'WhatsApp', 'WeChat'\n",
    "- Affects Academic Performance: 'Yes', 'No'\n",
    "- Relationship Status: 'In Relationship', 'Single', 'Complicated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values\n",
    "for col in cat_cols:\n",
    "    n_unique = df_data[col].nunique()\n",
    "    print(f'. {col}: has {n_unique} unique values')\n",
    "    if n_unique < 20:\n",
    "        print(f'   Unique values in {col}: {df_data[col].unique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data distribution\n",
    "- Here we study the distribution of each feature in the dataset.\n",
    "- We look for under-represented categoriesm, outliers, and skewness issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def plot_distributions(df, variables, plot_type='histogram'):\n",
    "    \"\"\"\n",
    "    Plot distributions for a list of variables in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the data\n",
    "    - variables: list of column names to plot\n",
    "    - plot_type: 'histogram' for continuous variables, 'countplot' for categorical variables\n",
    "    \"\"\"\n",
    "    n_cols = 3\n",
    "    n_rows = math.ceil(len(variables) / n_cols)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "    axes = axes.flatten()  # Flatten in case of single row\n",
    "\n",
    "    for i, var in enumerate(variables):\n",
    "        if plot_type == 'histogram':\n",
    "            sns.histplot(df[var], bins=30, binwidth=.3, kde=True, ax=axes[i])\n",
    "            axes[i].set_title(f'Distribution of {var}')\n",
    "            axes[i].set_xlabel(var)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "        elif plot_type == 'countplot':\n",
    "            sns.countplot(data=df, x=var, order=df[var].value_counts().index, ax=axes[i])\n",
    "            axes[i].set_title(f'Countplot of {var}')\n",
    "            axes[i].set_xlabel(var)\n",
    "            axes[i].set_ylabel('Count')\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Hide unused subplots (if any)\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms for numerical variables\n",
    "- Continuous variables have almost normal distributions based on the visual inspections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distributions(df_data, num_cols, plot_type='histogram')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness calculation\n",
    "- The skew function for 'Avg_Daily_Usage_Hours' and 'Sleep_Hours_Per_Night' is relatively close to 0, indicating that the distributions are close to normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "skew_cols = ['Daily_Usage', 'Sleep_Hrs']\n",
    "for var in skew_cols:\n",
    "    val = df_data[var].dropna()\n",
    "    sk = skew(val)\n",
    "    print(f\"{var}: Skewness = {sk:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countplots for categorical variables\n",
    "- The data is balanced between the genders, males and females are almost equal.\n",
    "- We have almost equal number of undergraduates and graduates (~325), but fewer high school students (~27).\n",
    "    - This may lead to high school students being under-represented in the dataset and may cause bias.\n",
    "- The majority of the participants are from India, USA, and Canada. \n",
    "    - There are ~80 countries with only 1 participant.\n",
    "    - Besides the bias, this may lead to overfitting in the modeling step.\n",
    "    - Possible options are:\n",
    "        - grouping the countries into regions or continents, \n",
    "        - dropping the countries with only 1 participant.\n",
    "        - frequency encoding the countries.\n",
    "- Students mostly use Instagram, Facebook, TikTok, and slightly less WhatsApp, while the rest of the platforms are used by 10-30 students with YouTube being the least used platform.\n",
    "    - Possibly this long tail distribution must be trimmed in the feature engineering step to avoid overfitting.\n",
    "    - Can be grouped into a few categories, or based on platform-type (social media, messaging, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplots for categorical variables\n",
    "count_plot_vars = cat_cols.copy()\n",
    "count_plot_vars.remove('Country')\n",
    "plot_distributions(df_data, count_plot_vars, plot_type='countplot')\n",
    "\n",
    "# plot the countplot for the country\n",
    "plt.figure(figsize=FIGSIZE_LONG)  # Set a wide figure size for better visualization\n",
    "\n",
    "sns.countplot(data=df_data, x='Country', order=df_data['Country'].value_counts().index)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group rations in under-represented demographic and behavioral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data['Relationship_Status'].value_counts(), end='\\n\\n')\n",
    "print(df_data['Academic_Level'].value_counts(), end='\\n\\n')\n",
    "print(df_data['Platform'].value_counts(), end='\\n\\n')\n",
    "print('number of countries with more than 1 participant: ', sum(df_data['Country'].value_counts()>1))\n",
    "print('number of countries with only 1 participant: ', sum(df_data['Country'].value_counts()==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual inspection using boxplots\n",
    "- We use boxplots to inspect the outliers visually.\n",
    "- In the boxplot, we can see that there are few outliers in the 'Avg_Daily_Usage_Hours'column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, len(num_cols) * .71))  # Dynamically adjust height\n",
    "sns.boxplot(data=df_data[num_cols], orient='h')  # Horizontal boxplots for each column\n",
    "plt.title('Boxplots of All Numeric Columns')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the outlier samples\n",
    "- We use the IQR method to detect the outliers.\n",
    "- The IQR method flags 3 potential outliers in the 'Avg_Daily_Usage_Hours' column where the student's daily usage was 1.5, and ~8.5 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'Daily_Usage'\n",
    "def find_outliers(df_data, column_name):\n",
    "    Q1 = df_data[column_name].quantile(0.25)\n",
    "    Q3 = df_data[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define outlier range\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter outliers\n",
    "    outliers = df_data[(df_data[column_name] < lower_bound) | (df_data[column_name] > upper_bound)]\n",
    "\n",
    "    # Inspect outliers\n",
    "    if len(outliers) > 0:\n",
    "        print(outliers[['Student_ID', column_name]])\n",
    "    else:\n",
    "        print(f\"No outliers found in {column_name}\")\n",
    "\n",
    "for column_name in num_cols:\n",
    "    find_outliers(df_data, column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier removal\n",
    "We use the IQR method to remove outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers using IQR method\n",
    "\n",
    "# define a function to remove outliers using IQR method\n",
    "def remove_outliers_iqr(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        df = df[~((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)))]\n",
    "    return df\n",
    "\n",
    "# remove outliers from the dataset\n",
    "df_data = remove_outliers_iqr(df_data, num_cols)\n",
    "\n",
    "# print the number of rows in the dataset\n",
    "print(f\"Number of rows in the original dataset: {len(df_data)}\")\n",
    "print(f\"Number of rows in the dataset: {len(df_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the cleaned dataset\n",
    "The cleaned dataset is saved in the data folder for modeling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned dataset using pickle\n",
    "\n",
    "# save the cleaned dataset\n",
    "df_data.to_pickle('../data/data_cleaned.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation matrices for numerical features\n",
    "- A strong positive correlation between 'Conflicts_Over_Social_Media' and 'Daily_Usage', \n",
    "- A strong negative correlation between 'Conflicts_Over_Social_Media' and 'Mental_Health'.\n",
    "    - However, the mental health score is determined by the student's self-perception, which may not be externally observable.\n",
    "- A mederate negative correlation between 'Conflicts_Over_Social_Media' and 'Sleep_Hours'.\n",
    "\n",
    "- Similar patterns are observed for 'Addicted_Score' and the input features.\n",
    "- A strong linear correlation between 'Daily_Usage_Hours', 'Mental_Health', and 'Sleep_Hours'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical columns\n",
    "numerical_cols = df_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "def plot_correlation_matrix(df_data, numerical_cols, method='pearson'):\n",
    "    # Compute correlation matrix\n",
    "    corr_pearson = df_data[numerical_cols].corr(method=method)\n",
    "    corr_spearman = df_data[numerical_cols].corr(method=method)\n",
    "\n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    # mask = np.triu(np.ones_like(corr_pearson, dtype=bool))\n",
    "    sns.heatmap(corr_pearson, annot=True, fmt=\".2f\", cmap=\"coolwarm\", \n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\n",
    "    plt.title(f'{method.capitalize()} Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "# Plot Pearson correlation heatmap\n",
    "plot_correlation_matrix(df_data, numerical_cols, method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plots for Relationship Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for selected features\n",
    "selected_features = ['Daily_Usage', 'Sleep_Hrs', \n",
    "                     'Mental_Health', 'Addicted_Score']\n",
    "sns.pairplot(df_data[num_cols], diag_kind='kde')\n",
    "plt.suptitle('Relationships Between Key Variables', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Distribution of Addicted Score by Categorical features:\n",
    " - gender, country, or platform.\n",
    " \n",
    " **Observations:**\n",
    " 1. **Gender**:\n",
    "   - The median addiction score is the same for males and females, however, female participants have more variability in their scores.\n",
    "\n",
    "2. **Academic Level**:\n",
    "   - The median of addicted score is close for all academic levels, between 7 and 8\n",
    "   - However, high school student samples contain outliers and generally have higher addicted scores.\n",
    "   - This observation might be due to the under-representation of high school students in the dataset.\n",
    " \n",
    "3. **Academic Affects**:\n",
    "   - Those who reported academic affects have a higher median addiction score.\n",
    "   - This strong correlation might be due to the self-reported nature of the question about academic affects.\n",
    "\n",
    "4. **Relationship Status**:\n",
    "   - Single individuals have a higher median addiction score compared to those in a relationship.\n",
    "   - Those in complicated relationships have a similar median addiction score compared to single participants, but most of them report higher addiction scores overall.\n",
    "   - This observation might be due to the under-representation of complicated relationship status in the dataset.\n",
    "   - The complicated group show outlier samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df_data' is your DataFrame and 'cat_cols' is your list of categorical columns\n",
    "boxplot_cols = cat_cols.copy()\n",
    "boxplot_cols.remove('Country')\n",
    "boxplot_cols.remove('Platform')\n",
    "\n",
    "def boxplot_by_category(df, boxplot_cols, target_col):\n",
    "    # Determine the number of rows and columns for the subplots\n",
    "    n_cols = 2  # Number of columns in the subplot grid\n",
    "    n_rows = (len(boxplot_cols) + n_cols - 1) // n_cols  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "    for i, col in enumerate(boxplot_cols):\n",
    "        n_cat = len(df[col].unique())\n",
    "        sns.boxplot(data=df, x=col, y=target_col, hue=col, ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {target_col} by {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel(target_col)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "boxplot_by_category(df_data, boxplot_cols, 'Addicted_Score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features with long-tail distributions:\n",
    "\n",
    "1. **Most Used Platforms**:\n",
    "    - People on Instagram and Twitter have a wider range of addiction scores compared to others with a relatively high median.\n",
    "    - Among popular platforms, Instagram, Tiktok, and WhatsApp have the highest median addiction scores. \n",
    "        - Tiktok: median = 8, WhatsApp: median = 7, Instagram: median = 7\n",
    "    - Tiktok and WhatsApp users have a comparable spread of addiction scores which are mostly high.\n",
    "    - Some outliers are observed in the Tiktok group.\n",
    "    - Other less popular platforms such as Snapchat, WeChat, Line, etc does not have enough data samples to make any strong statistical conclusions.\n",
    "\n",
    "2. **Countries (with more than 1 participant)**:\n",
    "    - USA shows the **highest addiction** scores with a median of 9 (maximum).\n",
    "    - India, Turkey, Mexico, Spain, and UK show similar spread of addiction scores. They are in the **2nd tier** after USA.\n",
    "    - Japan shows the **lowest addiction** scores spread among all well-represented countries.\n",
    "    - Countries like Switzerland, Denmark, Germany, France, and Australia are in the **middle tier**.\n",
    "    - The rest of the coutries show above average addiction score spreads.\n",
    "    - The countries with less than 10 participants show a binary distribution of addiction scores which may indicate sampling bias. \n",
    "      - It's important to treat this feature with care in the modeling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Platform separately\n",
    "def boxplot_by_category_long_tail(df, cat_cols, target_col):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.boxplot(data=df, x=cat_cols, y=target_col, hue=cat_cols, order=df[cat_cols].value_counts().index)\n",
    "    plt.title(f'Distribution of {target_col} by {cat_cols} - order by number of participants')\n",
    "    plt.xlabel(cat_cols)\n",
    "    plt.ylabel(target_col)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "boxplot_by_category_long_tail(df_data, 'Platform', 'Addicted_Score')\n",
    "\n",
    "# boxplot for countries with more than 1 participant\n",
    "df_data_country = df_data[df_data['Country'].isin(df_data['Country'].value_counts()[df_data['Country'].value_counts() > 1].index)]\n",
    "boxplot_by_category_long_tail(df_data_country, 'Country', 'Addicted_Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Distribution of Conflicts over Social Media by Categorical features:\n",
    " - gender, country, or platform.\n",
    " \n",
    "**Observations:**\n",
    "- The boxplots show distributions similar to the addiction score boxplots.\n",
    "- The conflicts distributions for high school students and those with no academic affects have a tight spread.\n",
    "- The conflicts are more similar among the 3 relationship status groups compared to their reported addiction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_by_category(df_data, boxplot_cols, 'Conflicts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features with long-tail distributions:\n",
    "- For Most Used Platforms and Countries the distributions of Social Media Conflicts are similar to the Addicted Score distributions.\n",
    "- However, Instagram users show relatively less conflicts compared to their addiction scores next to other platforms. \n",
    "- Among countries, Ireland, Denmark, Switzerland, and Canada show a tight conflict spread compared to their addiction scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Conflicts'\n",
    "\n",
    "boxplot_by_category_long_tail(df_data, 'Platform', target_col)\n",
    "\n",
    "# boxplot for countries with more than 1 participant\n",
    "df_data_country = df_data[df_data['Country'].isin(df_data['Country'].value_counts()[df_data['Country'].value_counts() > 1].index)]\n",
    "boxplot_by_category_long_tail(df_data_country, 'Country', target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create grouped bar plots for average comparison\n",
    "def plot_grouped_averages(df, category_col, value_cols, figsize = (14,5)):\n",
    "    \"\"\"\n",
    "    Create grouped bar plots to compare averages across categories\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data\n",
    "    - category_col: Column name for categories (x-axis)\n",
    "    - value_cols: List of column names for values to compare\n",
    "    \"\"\"\n",
    "    # Calculate group averages\n",
    "    group_avgs = df.groupby(category_col)[value_cols].mean().reset_index()\n",
    "    \n",
    "    # Reshape data for plotting\n",
    "    melted_df = pd.melt(group_avgs, id_vars=[category_col], \n",
    "                        value_vars=value_cols,\n",
    "                        var_name='Metric', value_name='Average Value')\n",
    "    \n",
    "    # Create the grouped bar plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.barplot(data=melted_df, x=category_col, y='Average Value', hue='Metric')\n",
    "    plt.title(f'Average Metrics by {category_col}')\n",
    "    plt.xlabel(category_col)\n",
    "    plt.ylabel('Average Value')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Metric')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "value_columns = ['Addicted_Score', 'Mental_Health', 'Sleep_Hrs']\n",
    "\n",
    "# By platform\n",
    "plot_grouped_averages(df_data, 'Platform', value_columns)\n",
    "\n",
    "# By gender\n",
    "plot_grouped_averages(df_data, 'Gender', value_columns, (6,4))\n",
    "\n",
    "# By age group (create age groups first)\n",
    "df_data['Age_Group'] = pd.cut(df_data['Age'], bins=[15, 20, 25], labels=['16-20', '21-25'])\n",
    "plot_grouped_averages(df_data, 'Age_Group', value_columns, (6,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the class imbalance for the Social Media Conflicts\n",
    "- **Binary Conflict Variable**:\n",
    "    - Grouping the conflicts into 2 classes (0-3 vs 4-5) shows a class imbalance ratio of 2.73:1.\n",
    "    - Grouping the conflicts into 3 classes (0-2 vs 3 vs 4-5) shows a weaker class imbalance ratio of 1.76:1.\n",
    "- **3 Class Conflict Variable**:\n",
    "    - The 3-class mapping of conflicts target (0-2 vs 3 vs 4-5) shows a class imbalance ratio of 1.37:1.\n",
    "- A 3-class mapping of target conflicts variable is more balanced and interpretable compare to the binary mapping.\n",
    "- Among binary classification settings, the one with conflicts < 3 against the rest shows a better class balance.\n",
    "- A 2-class problem is less complex than a 3-class one, but it might need data downsampling or oversampling to avoid overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert Conflicts_Over_Social_Media into binary categories\n",
    "# First, let's examine the distribution to determine a meaningful threshold\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df_data['Conflicts'], kde=True)\n",
    "plt.axvline(df_data['Conflicts'].median(), color='red', linestyle='--', \n",
    "           label=f'Median = {df_data[\"Conflicts\"].median()}')\n",
    "plt.title('Distribution of Conflicts Over Social Media')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def create_binary_conflic(df, threshold):\n",
    "    # Create binary target variable based on median split\n",
    "    # median_conflict = df_data['Conflicts'].median()\n",
    "    df['Conflict_Binary'] = df['Conflicts'].apply(\n",
    "        lambda x: 'High' if x > threshold else 'Low'\n",
    "    )\n",
    "\n",
    "    # Check the distribution of the binary variable\n",
    "    conflict_counts = df['Conflict_Binary'].value_counts()\n",
    "    print(f\"Binary Conflict Distribution: ({0}-{threshold}) vs ({threshold+1}-5)\")\n",
    "    print(conflict_counts)\n",
    "    print(f\"Class imbalance ratio: {conflict_counts.max() / conflict_counts.min():.2f}\")\n",
    "\n",
    "    # Visualize the binary distribution\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.countplot(data=df, x='Conflict_Binary')\n",
    "    plt.title(f'Distribution of Binary Conflict Variable:\\n ({0}-{threshold}) vs ({threshold+1}-5)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "create_binary_conflic(df_data, 3)\n",
    "create_binary_conflic(df_data, 2)\n",
    "\n",
    "# a 3 class mapping\n",
    "df_data['Conflict_3_Class'] = df_data['Conflicts'].apply(\n",
    "    lambda x: 'High' if x >= 4 else 'Medium' if x == 3  else 'Low'\n",
    ")\n",
    "\n",
    "# Check the distribution of the 3 class variable\n",
    "conflict_counts = df_data['Conflict_3_Class'].value_counts()\n",
    "print(f\"3 Class Conflict Distribution: ({0}-2) vs (3) vs ({4}-5)\")\n",
    "print(conflict_counts)\n",
    "print(f\"Class imbalance ratio: {conflict_counts.max() / conflict_counts.min():.2f}\")\n",
    "# Plot the 3 class distribution\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.countplot(data=df_data, x='Conflict_3_Class')\n",
    "plt.title('Distribution of 3 Class Conflict Variable:\\n (0-2) vs (3) vs (4-5)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical variables\n",
    "We use the following encoding methods:\n",
    "- Binary encoding for binary categorical variables\n",
    "- One-hot encoding for categorical variables with more than 2 categories while leaving the smallest category as \"others\"\n",
    "- Frequency encoding for categorical variables with high cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Feature Encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Create a copy of the dataframe for encoding\n",
    "df_encoded = df_data.copy()\n",
    "\n",
    "# 1. Binary encoding for Gender\n",
    "le_gender = LabelEncoder()\n",
    "df_encoded['Gender_encoded'] = le_gender.fit_transform(df_encoded['Gender'])\n",
    "print(\"Gender encoding:\")\n",
    "print(f\"Female -> {le_gender.transform(['Female'])[0]}\")\n",
    "print(f\"Male -> {le_gender.transform(['Male'])[0]}\")\n",
    "\n",
    "# plot the distribution of the encoded variable\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.countplot(data=df_encoded, x='Gender_encoded')\n",
    "plt.title('Distribution of Gender Encoded Variable')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding for categorical features\n",
    "We use the one-hot encoding for Relationship_Status and Academic_Level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. One-hot encoding for Relationship_Status and Academic_Level\n",
    "def encode_onehot_with_reference(df, column_name, prefix=None):\n",
    "    \"\"\"One-hot encoding with smallest category as reference (dropped)\"\"\"\n",
    "    counts = df[column_name].value_counts()\n",
    "    smallest_category = counts.index[-1]  # Get smallest category\n",
    "    \n",
    "    print(f\"\\n Encoding {column_name} with prefix {prefix}\")\n",
    "    print(f\"Reference category (dropped): {smallest_category}\")\n",
    "    \n",
    "    # Create one-hot encoded columns\n",
    "    dummies = pd.get_dummies(df[column_name], prefix=prefix or column_name, drop_first=False)\n",
    "    # Drop smallest category as reference\n",
    "    dummies = dummies.drop(f'{prefix or column_name}_{smallest_category}', axis=1)\n",
    "\n",
    "    # print the first 5 rows of the encoded variable\n",
    "    print(dummies.head())\n",
    "\n",
    "   \n",
    "    # Concatenate with original dataframe\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    # print samples of the other category\n",
    "    print(f\"\\nSamples of the other category:\")\n",
    "    mask = df[column_name] == smallest_category\n",
    "    print(pd.concat([df[mask][[column_name]], dummies[mask]], axis=1).head())\n",
    "\n",
    "    return df, dummies\n",
    "\n",
    "# For Relationship_Status - find the smallest category to use as 'other'\n",
    "df_encoded, dummies_rel = encode_onehot_with_reference(df_encoded, 'Relationship_Status', 'Relationship')\n",
    "\n",
    "# For Academic_Level - find the smallest category to use as 'other'\n",
    "df_encoded, dummies_acad = encode_onehot_with_reference(df_encoded, 'Academic_Level', 'Academic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping for Platform and Country inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping Platforms with category size less than 10% of the total\n",
    "\n",
    "# group the platforms with category size less than 10% of the total\n",
    "df_encoded['Platform_group'] = df_encoded['Platform'].apply(lambda x: 'Other' if df_encoded['Platform'].value_counts()[x] < 30 else x)\n",
    "\n",
    "# print the distribution of the platform_group variable\n",
    "print(df_encoded['Platform_group'].value_counts())\n",
    "\n",
    "# plot the distribution of the Platform_group variable\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.countplot(data=df_encoded, x='Platform_group')\n",
    "plt.title('Distribution of Platform Group Encoded Variable')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# one-hot encode the platform_group variable\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=['Platform_group'], prefix='Platform')\n",
    "# print(df_encoded['Platform_group'].head())\n",
    "\n",
    "col_platform_group = [col for col in df_encoded.columns if 'Platform' in col]\n",
    "df_encoded[col_platform_group].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Country "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping non-dominent countries into a single category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping Platforms with category size less than 10% of the total\n",
    "\n",
    "# group the country with category size less than 10% of the total\n",
    "df_encoded['Country_group'] = df_encoded['Country'].apply(\n",
    "    lambda x: 'Other' if df_encoded['Country'].value_counts()[x] < 20 else x\n",
    "    )\n",
    "\n",
    "# print the distribution of the platform_group variable\n",
    "print(df_encoded['Country_group'].value_counts())\n",
    "\n",
    "# plot the distribution of the Platform_group variable\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.countplot(data=df_encoded, x='Country_group')\n",
    "plt.title('Distribution of Country Group Encoded Variable')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# one-hot encode the platform_group variable\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=['Country_group'], prefix='Country')\n",
    "# print(df_encoded['Platform_group'].head())\n",
    "\n",
    "col_platform_group = [col for col in df_encoded.columns if 'Country' in col]\n",
    "df_encoded[col_platform_group].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Frequency-based encoding for Country and Platform\n",
    "def encode_frequency(df, column_name):\n",
    "    freq = df[column_name].value_counts().to_dict()\n",
    "    df[f'{column_name}_freq_encoded'] = df[column_name].map(freq)\n",
    "\n",
    "    # print the first 5 rows of the encoding mapping   \n",
    "    print(f\"\\n{column_name} frequency encoding (top 5):\")\n",
    "    for country, freq in list(freq.items())[:5]:\n",
    "        print(f\"{country}: {freq}\")\n",
    "\n",
    "    # print the first 5 rows of the encoded variable\n",
    "    print(f\"\\n{column_name} frequency encoded variable (top 5):\")\n",
    "    print(df[[f'{column_name}_freq_encoded']].head())\n",
    "\n",
    "    # plot encoded variable distribution\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    sns.countplot(data=df, x=f'{column_name}_freq_encoded')\n",
    "    plt.title(f'Distribution of {column_name} Encoded Variable')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Country frequency encoding\n",
    "df_encoded =  encode_frequency(df_encoded, 'Country')\n",
    "df_encoded =  encode_frequency(df_encoded, 'Platform')\n",
    "# df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continent-based encoding for Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping countries by continent\n",
    "df_data = map_to_continent(df_data)\n",
    "\n",
    "#  visualize\n",
    "plt.figure(figsize=(8, 3))\n",
    "sns.countplot(data=df_data, x='Continent', hue='Conflict_Binary')\n",
    "plt.title('Distribution of Continent Variable')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c29env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
